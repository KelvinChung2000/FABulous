{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd9356d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "=== NextPNR Parameter Sweep with MLIR Processing Pipeline ===\n",
      "Comprehensive FPGA parameter optimization using MLIR-generated benchmarks\n",
      "Auto-reload enabled for module imports\n",
      "âœ“ Core libraries and logging configured\n"
     ]
    }
   ],
   "source": [
    "# NextPNR Parameter Sweep with MLIR Processing Pipeline\n",
    "# Comprehensive tool for FPGA parameter optimization using MLIR-generated benchmarks\n",
    "\n",
    "# Enable auto reload for imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard library imports\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import concurrent.futures\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Configure loguru logger - output only to stdout (only if not already configured)\n",
    "# logger.remove()  # Remove default handler\n",
    "# logger.add(sys.stdout, format=\"{time} | {level} | {message}\", level=\"INFO\")\n",
    "\n",
    "print(\"=== NextPNR Parameter Sweep with MLIR Processing Pipeline ===\")\n",
    "print(\"Comprehensive FPGA parameter optimization using MLIR-generated benchmarks\")\n",
    "print(\"Auto-reload enabled for module imports\")\n",
    "\n",
    "print(\"âœ“ Core libraries and logging configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3abde904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration setup complete:\n",
      "  Parameter combinations: 10 Ã— 10 = 100 total\n",
      "  Test grid size: 100 combinations\n",
      "  Compilation results directory: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result\n",
      "  Stage directories:\n",
      "    01_optimized_mlir/ - MLIR optimization results\n",
      "    02_extracted_mlir/ - Loop-to-function extraction results\n",
      "    03_intermediate_mlir/ - Individual function MLIR files\n",
      "    04_futil/ - Generated FUTIL files\n",
      "    05_verilog/ - Final Verilog output\n",
      "  Parameter sweep results directory: /home/kelvin/FABulous_fork/myProject/PnR/parameter_sweep_results\n",
      "  Benchmark root directory: /home/kelvin/FABulous_fork/myProject/PnR/mlir\n",
      "  Starting with unoptimized MLIR files from BENCHMARK folder\n",
      "âœ“ Configuration and paths set up successfully\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Parameter Setup\n",
    "# Define parameter ranges, paths, and constants for the parameter sweep\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define parameter ranges for the sweep\n",
    "CONNECTIVITY_FACTORS = np.arange(0.0, 2.0, 0.2)  # 0.0 to 2.0 with step 0.2\n",
    "CONGESTION_FACTORS = np.arange(0.0, 2.0, 0.2)    # 0.0 to 2.0 with step 0.2\n",
    "\n",
    "# Create parameter grid - use reduced set for testing or full grid for production\n",
    "grid = list(itertools.product(CONNECTIVITY_FACTORS, CONGESTION_FACTORS))  # Full grid\n",
    "# grid = [(0, 0), (0, 1), (1, 0), (1, 1)]  # Reduced grid for testing\n",
    "\n",
    "# software dir configuration\n",
    "CALYX_PATH: str = \"/home/kelvin/calyx\"\n",
    "MLIR_OPT_PATH: str = \"/home/kelvin/circt/build/vscode/bin/mlir-opt\"\n",
    "HLSTOOL_PATH: str = \"/home/kelvin/circt/build/vscode/bin/hlstool\"\n",
    "\n",
    "# Project and directory configuration\n",
    "MY_FAB_ROOT: Path = Path(\"/home/kelvin/FABulous_fork\")\n",
    "FAB_PROJ_DIR: Path = Path(\"/home/kelvin/FABulous_fork/myProject\")\n",
    "\n",
    "# Compilation results directory structure - Stage-based organization\n",
    "COMPILATION_RESULT_DIR: Path = Path(\"/home/kelvin/FABulous_fork/myProject/PnR/compilation_result\")\n",
    "\n",
    "# Stage-specific directories for cleaner organization and simpler naming\n",
    "MLIR_OPTIMIZED_DIR: Path = COMPILATION_RESULT_DIR / \"01_optimized_mlir\"\n",
    "MLIR_EXTRACTED_DIR: Path = COMPILATION_RESULT_DIR / \"02_extracted_mlir\"\n",
    "FUTIL_OUTPUT_DIR: Path = COMPILATION_RESULT_DIR / \"03_futil\"\n",
    "VERILOG_OUTPUT_DIR: Path = COMPILATION_RESULT_DIR / \"04_verilog\"\n",
    "SYNTHESIS_OUTPUT_DIR: Path = COMPILATION_RESULT_DIR / \"05_synthesis\"\n",
    "PNR_OUTPUT_DIR: Path = COMPILATION_RESULT_DIR / \"06_PNR\"\n",
    "OUTPUT_DIR: Path = Path(\"/home/kelvin/FABulous_fork/myProject/PnR/parameter_sweep_results\")\n",
    "\n",
    "# Benchmark directory configuration - MLIR files only\n",
    "BENCHMARK_ROOT_DIR: Path = Path(\"/home/kelvin/FABulous_fork/myProject/PnR/mlir\")\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ[\"FAB_PROJ_DIR\"] = str(FAB_PROJ_DIR)\n",
    "os.environ[\"PATH\"] = f\"/home/kelvin/nextpnr/build/bba:{os.environ['PATH']}\"\n",
    "os.environ[\"PATH\"] = f\"/home/kelvin/nextpnr/build:{os.environ['PATH']}\"\n",
    "os.environ[\"PATH\"] = f\"/home/kelvin/yosys:{os.environ['PATH']}\"\n",
    "os.environ[\"PATH\"] = f\"/home/kelvin/circt/build/bin:{os.environ['PATH']}\"\n",
    "os.environ[\"CALYX_PRIMITIVES_DIR\"] = str(Path(CALYX_PATH))\n",
    "\n",
    "# Create necessary directories for all processing stages\n",
    "COMPILATION_RESULT_DIR.mkdir(exist_ok=True)\n",
    "MLIR_OPTIMIZED_DIR.mkdir(exist_ok=True)\n",
    "MLIR_EXTRACTED_DIR.mkdir(exist_ok=True)\n",
    "FUTIL_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "VERILOG_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# FABulous file paths\n",
    "CHIPDB_PATH = FAB_PROJ_DIR / \".FABulous/hycube.bit\"\n",
    "JSON_INPUT = FAB_PROJ_DIR / \"user_design/synth_test.json\"\n",
    "CONSTRAIN_PAIR = FAB_PROJ_DIR / \".FABulous/hycube_constrain_pair.inc\"\n",
    "FDC_PATH = FAB_PROJ_DIR / \"user_design/test.fdc\"\n",
    "\n",
    "# Fallback source file if no generated Verilog files are available\n",
    "FALLBACK_SOURCE_HDL = MY_FAB_ROOT / \"benchmarks/userbench/loop_array_inner/loop_array_inner.sv\"\n",
    "\n",
    "# Fixed parameters for nextpnr runs\n",
    "BETA_VALUE = 0.9\n",
    "PLACE_TRIALS = 1\n",
    "ROUTER_TIMEOUT = 20000\n",
    "\n",
    "# Initialize available MLIR files and Verilog files structures\n",
    "availableMlirFiles = []\n",
    "availableVerilogFiles = []\n",
    "benchmarkStructure = {}\n",
    "\n",
    "print(\"Configuration setup complete:\")\n",
    "print(f\"  Parameter combinations: {len(CONNECTIVITY_FACTORS)} Ã— {len(CONGESTION_FACTORS)} = {len(CONNECTIVITY_FACTORS) * len(CONGESTION_FACTORS)} total\")\n",
    "print(f\"  Test grid size: {len(grid)} combinations\")\n",
    "print(f\"  Compilation results directory: {COMPILATION_RESULT_DIR}\")\n",
    "print(\"  Stage directories:\")\n",
    "print(\"    01_optimized_mlir/ - MLIR optimization results\")\n",
    "print(\"    02_extracted_mlir/ - Loop-to-function extraction results\")\n",
    "print(\"    03_intermediate_mlir/ - Individual function MLIR files\")\n",
    "print(\"    04_futil/ - Generated FUTIL files\")\n",
    "print(\"    05_verilog/ - Final Verilog output\")\n",
    "print(f\"  Parameter sweep results directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Benchmark root directory: {BENCHMARK_ROOT_DIR}\")\n",
    "print(\"  Starting with unoptimized MLIR files from BENCHMARK folder\")\n",
    "\n",
    "print(\"âœ“ Configuration and paths set up successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377a4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced data structures for complete pipeline\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "from enum import Enum\n",
    "import time\n",
    "import os\n",
    "\n",
    "class FailureType(Enum):\n",
    "    NONE = \"none\"\n",
    "    MLIR_OPTIMIZATION = \"mlir_optimization\"\n",
    "    LOOP_EXTRACTION = \"loop_extraction\" \n",
    "    FUTIL_GENERATION = \"futil_generation\"\n",
    "    VERILOG_GENERATION = \"verilog_generation\"\n",
    "    SYNTHESIS = \"synthesis\"\n",
    "    PLACEMENT = \"placement\"\n",
    "    ROUTING = \"routing\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "@dataclass\n",
    "class VerilogPipelineResult:\n",
    "    \"\"\"Unified MLIR to Verilog generation pipeline result\"\"\"\n",
    "    source_file: Path\n",
    "    success: bool\n",
    "    runtime: float\n",
    "    \n",
    "    # Output files\n",
    "    optimized_mlir_file: Optional[Path] = None\n",
    "    function_extracted: Optional[list[Path]] = None\n",
    "    futil_files: Optional[list[Path]] = None\n",
    "    verilog_files: Optional[list[Path]] = None\n",
    "    \n",
    "    # Stage metrics\n",
    "    mlir_optimization_time: float = 0.0\n",
    "    loop_extraction_time: float = 0.0\n",
    "    futil_generation_time: float = 0.0\n",
    "\n",
    "    \n",
    "    # Error tracking\n",
    "    failure_stage: Optional[FailureType] = None\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.verilog_files is None:\n",
    "            self.verilog_files = []\n",
    "\n",
    "@dataclass\n",
    "class SynthesisResult:\n",
    "    \"\"\"FABulous synthesis preprocessing result\"\"\"\n",
    "    success: bool\n",
    "    runtime: float\n",
    "    verilog_file: Optional[Path] = None\n",
    "    synthesis_out_file: Optional[Path] = None\n",
    "    error_message: Optional[str] = None\n",
    "    full_stdout: Optional[str] = None\n",
    "    full_stderr: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class ParameterResult:\n",
    "    \"\"\"Single parameter configuration result\"\"\"\n",
    "    config_id: int\n",
    "    success: bool\n",
    "    runtime: float\n",
    "    \n",
    "    # Configuration parameters\n",
    "    parameters: Dict[str, Any] = None\n",
    "    \n",
    "    # NextPNR analysis results\n",
    "    placement_info: Optional[Dict[str, Any]] = None\n",
    "    routing_info: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    full_stdout: Optional[str] = None\n",
    "    full_stderr: Optional[str] = None\n",
    "    \n",
    "    # Error tracking\n",
    "    failure_type: Optional[FailureType] = None\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.parameters is None:\n",
    "            self.parameters = {}\n",
    "\n",
    "@dataclass\n",
    "class CompletePipelineResult:\n",
    "    \"\"\"Complete end-to-end pipeline result\"\"\"\n",
    "    source_file: Path\n",
    "    overall_success: bool\n",
    "    total_runtime: float\n",
    "    \n",
    "    # Stage results\n",
    "    verilog_pipeline: VerilogPipelineResult\n",
    "    synthesis_results: List[SynthesisResult]  # Updated to handle multiple synthesis results\n",
    "    parameter_results: List[ParameterResult]\n",
    "    \n",
    "    # Overall failure tracking\n",
    "    primary_failure_type: FailureType = FailureType.NONE\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for DataFrame creation\"\"\"\n",
    "        base_dict = {\n",
    "            'source_file': os.path.basename(self.source_file),\n",
    "            'overall_success': self.overall_success,\n",
    "            'total_runtime': self.total_runtime,\n",
    "            'primary_failure': self.primary_failure_type.value,\n",
    "            \n",
    "            # Verilog pipeline\n",
    "            'verilog_success': self.verilog_pipeline.success,\n",
    "            'verilog_runtime': self.verilog_pipeline.runtime,\n",
    "            'mlir_opt_time': self.verilog_pipeline.mlir_optimization_time,\n",
    "            'loop_extract_time': self.verilog_pipeline.loop_extraction_time,\n",
    "            'futil_gen_time': self.verilog_pipeline.futil_generation_time,\n",
    "            'function_extracted': self.verilog_pipeline.function_extracted,\n",
    "            \n",
    "            # Synthesis - aggregated metrics from multiple synthesis results\n",
    "            'synthesis_count': len(self.synthesis_results),\n",
    "            'synthesis_success_count': sum(1 for s in self.synthesis_results if s.success),\n",
    "            'synthesis_overall_success': any(s.success for s in self.synthesis_results),\n",
    "            'synthesis_total_runtime': sum(s.runtime for s in self.synthesis_results),\n",
    "            'synthesis_avg_runtime': sum(s.runtime for s in self.synthesis_results) / len(self.synthesis_results) if self.synthesis_results else 0,\n",
    "            \n",
    "            # Parameter sweep summary\n",
    "            'total_configs': len(self.parameter_results),\n",
    "            'successful_configs': sum(1 for p in self.parameter_results if p.success),\n",
    "        }\n",
    "        \n",
    "        if self.parameter_results:\n",
    "            successful_params = [p for p in self.parameter_results if p.success]\n",
    "            if successful_params:\n",
    "                base_dict['avg_param_runtime'] = sum(p.runtime for p in successful_params) / len(successful_params)\n",
    "                base_dict['min_param_runtime'] = min(p.runtime for p in successful_params)\n",
    "                base_dict['max_param_runtime'] = max(p.runtime for p in successful_params)\n",
    "        \n",
    "        return base_dict\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        String representation for displaying pipeline result information.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Formatted summary of the pipeline result.\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        lines.append(f\"Pipeline Result for: {self.source_file}\")\n",
    "        lines.append(f\"  Overall Success: {self.overall_success}\")\n",
    "        lines.append(f\"  Total Runtime: {self.total_runtime:.2f}s\")\n",
    "        lines.append(f\"  Primary Failure: {self.primary_failure_type.value}\")\n",
    "        lines.append(\"  Verilog Pipeline:\")\n",
    "        lines.append(f\"    Success: {self.verilog_pipeline.success}\")\n",
    "        lines.append(f\"    Runtime: {self.verilog_pipeline.runtime:.2f}s\")\n",
    "        lines.append(f\"    MLIR Opt Time: {self.verilog_pipeline.mlir_optimization_time:.2f}s\")\n",
    "        lines.append(f\"    Loop Extract Time: {self.verilog_pipeline.loop_extraction_time:.2f}s\")\n",
    "        lines.append(f\"    FUTIL Gen Time: {self.verilog_pipeline.futil_generation_time:.2f}s\")\n",
    "        if self.verilog_pipeline.function_extracted:\n",
    "            lines.append(f\"    function extracted: {self.verilog_pipeline.function_extracted}\")\n",
    "        if self.verilog_pipeline.failure_stage:\n",
    "            lines.append(f\"    Failure Stage: {self.verilog_pipeline.failure_stage.value}\")\n",
    "        if self.verilog_pipeline.error_message:\n",
    "            lines.append(f\"    Error: {self.verilog_pipeline.error_message}\")\n",
    "        \n",
    "        # Updated synthesis section to handle multiple results\n",
    "        lines.append(\"  Synthesis:\")\n",
    "        lines.append(f\"    Total Synthesis Jobs: {len(self.synthesis_results)}\")\n",
    "        successful_synthesis = sum(1 for s in self.synthesis_results if s.success)\n",
    "        lines.append(f\"    Successful: {successful_synthesis}/{len(self.synthesis_results)}\")\n",
    "        if self.synthesis_results:\n",
    "            total_synthesis_runtime = sum(s.runtime for s in self.synthesis_results)\n",
    "            lines.append(f\"    Total Runtime: {total_synthesis_runtime:.2f}s\")\n",
    "            lines.append(f\"    Average Runtime: {total_synthesis_runtime/len(self.synthesis_results):.2f}s\")\n",
    "            \n",
    "            # Show details for failed synthesis\n",
    "            failed_synthesis = [s for s in self.synthesis_results if not s.success]\n",
    "            if failed_synthesis:\n",
    "                lines.append(f\"    Failed synthesis errors:\")\n",
    "                for i, s in enumerate(failed_synthesis):\n",
    "                    if s.error_message:\n",
    "                        lines.append(f\"      {i+1}. {s.error_message}\")\n",
    "        \n",
    "        lines.append(\"  Parameter Sweep:\")\n",
    "        lines.append(f\"    Total Configs: {len(self.parameter_results)}\")\n",
    "        successful_params = sum(1 for p in self.parameter_results if p.success)\n",
    "        lines.append(f\"    Successful Configs: {successful_params}\")\n",
    "        if self.parameter_results:\n",
    "            failures = [p for p in self.parameter_results if not p.success]\n",
    "            if failures:\n",
    "                lines.append(f\"    Failed Configs: {len(failures)}\")\n",
    "                failure_types = {}\n",
    "                for p in failures:\n",
    "                    ft = p.failure_type.value if p.failure_type else \"unknown\"\n",
    "                    failure_types[ft] = failure_types.get(ft, 0) + 1\n",
    "                for ft, count in failure_types.items():\n",
    "                    lines.append(f\"      {ft}: {count}\")\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10fa5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct pipeline functions with proper stage directories\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import io\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "def run_verilog_pipeline(mlir_file: Path) -> VerilogPipelineResult:\n",
    "    \"\"\"\n",
    "    Run the complete MLIR to Verilog generation pipeline with stage directories\n",
    "    MLIR optimization -> Loop extraction -> FUTIL generation -> Verilog generation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    mlir_path = Path(mlir_file)\n",
    "    base_name = mlir_path.stem\n",
    "    \n",
    "    result = VerilogPipelineResult(\n",
    "        source_file=mlir_file,\n",
    "        success=False,\n",
    "        runtime=0.0,\n",
    "        verilog_files=[]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Stage 1: MLIR Optimization\n",
    "        mlir_start = time.time()\n",
    "        optimized_mlir_path = MLIR_OPTIMIZED_DIR / f\"{base_name}.mlir\"\n",
    "        result.optimized_mlir_file, mlir_success, mlir_error = run_mlir_optimization(mlir_path, optimized_mlir_path)\n",
    "        result.mlir_optimization_time = time.time() - mlir_start\n",
    "        \n",
    "        if not mlir_success or result.optimized_mlir_file is None:\n",
    "            result.failure_stage = FailureType.MLIR_OPTIMIZATION\n",
    "            result.error_message = mlir_error or \"MLIR optimization failed\"\n",
    "            result.runtime = time.time() - start_time\n",
    "            return result\n",
    "        \n",
    "        # Stage 2: Loop Extraction - now returns list of files\n",
    "        loop_start = time.time()\n",
    "        result.function_extracted, loop_success, loop_error = extract_loops_from_mlir(Path(result.optimized_mlir_file), MLIR_EXTRACTED_DIR)\n",
    "        result.loop_extraction_time = time.time() - loop_start\n",
    "        \n",
    "        if not loop_success:\n",
    "            result.failure_stage = FailureType.LOOP_EXTRACTION\n",
    "            result.error_message = loop_error or \"Loop extraction failed\"\n",
    "            result.runtime = time.time() - start_time\n",
    "            return result\n",
    "        \n",
    "        # Stage 3 & 4: Process each extracted file through FUTIL -> Verilog\n",
    "        all_verilog_files = []\n",
    "        all_futil_files = []\n",
    "        for extracted_file in result.function_extracted:\n",
    "            # FUTIL Generation for this file\n",
    "            futil_start = time.time()\n",
    "            futil_file, futil_success, futil_error = generate_futil_from_mlir(extracted_file, FUTIL_OUTPUT_DIR)\n",
    "            all_futil_files.append(futil_file)\n",
    "            futil_time = time.time() - futil_start\n",
    "            result.futil_generation_time += futil_time\n",
    "            \n",
    "            if not futil_success or futil_file is None:\n",
    "                result.failure_stage = FailureType.FUTIL_GENERATION\n",
    "                result.error_message = futil_error or f\"FUTIL generation failed for {extracted_file}\"\n",
    "                result.runtime = time.time() - start_time\n",
    "                return result\n",
    "            \n",
    "            # Verilog Generation for this FUTIL file\n",
    "            verilog_file, verilog_success, verilog_error = generate_verilog_from_futil(futil_file, VERILOG_OUTPUT_DIR)\n",
    "            \n",
    "            if not verilog_success or not verilog_file:\n",
    "                result.failure_stage = FailureType.VERILOG_GENERATION\n",
    "                result.error_message = verilog_error or f\"Verilog generation failed for {futil_file}\"\n",
    "                result.runtime = time.time() - start_time\n",
    "                return result\n",
    "                \n",
    "            all_verilog_files.append(verilog_file)\n",
    "        \n",
    "        result.verilog_files = all_verilog_files\n",
    "        result.futil_files = all_futil_files\n",
    "        result.success = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        result.failure_stage = FailureType.VERILOG_GENERATION\n",
    "        result.error_message = str(e)\n",
    "    \n",
    "    result.runtime = time.time() - start_time\n",
    "    return result\n",
    "\n",
    "def run_mlir_optimization(mlir_file: Path, output_path: Path) -> Tuple[Optional[Path], bool, Optional[str]]:\n",
    "    \"\"\"Run MLIR optimization passes - returns (output_file, success, error_message)\"\"\"\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        cmd = [\n",
    "            \"mlir-opt\",\n",
    "            \"--allow-unregistered-dialect\",\n",
    "            \"--int-range-optimizations\",\n",
    "            \"--sroa\",\n",
    "            \"--normalize-memrefs\", \n",
    "            \"--flatten-memref\",\n",
    "            \"--enable-loop-simplifycfg-term-folding\",\n",
    "            \"--affine-loop-fusion\",\n",
    "            \"--affine-simplify-structures\",\n",
    "            \"--affine-loop-invariant-code-motion\",\n",
    "            \"--affine-scalrep\",\n",
    "            \"--affine-pipeline-data-transfer\",\n",
    "            \"-mlir-print-op-generic\",\n",
    "            str(mlir_file),\n",
    "            '-o', str(output_path)\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
    "        \n",
    "        if result.returncode == 0 and output_path.exists():\n",
    "            return output_path, True, None\n",
    "        else:\n",
    "            error_msg = f\"MLIR optimization failed: {result.stderr}\"\n",
    "            return None, False, error_msg\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return None, False, \"MLIR optimization timed out\"\n",
    "    except Exception as e:\n",
    "        return None, False, f\"MLIR optimization error: {str(e)}\"\n",
    "\n",
    "def extract_loops_from_mlir(optimized_mlir_file: Path, extracted_dir: Path) -> Tuple[List[Path], bool, Optional[str]]:\n",
    "    \"\"\"Extract loops using inner_loop_to_func - returns (list_of_extracted_files, success, error_message)\"\"\"\n",
    "    try:\n",
    "        # Ensure directory exists\n",
    "        extracted_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        from inner_loop_to_func import process_mlir_file\n",
    "        extracted_file_paths = process_mlir_file(str(optimized_mlir_file), str(extracted_dir), False)\n",
    "        if extracted_file_paths:\n",
    "            return extracted_file_paths, True, None\n",
    "        else:\n",
    "            return [], False, \"No loops extracted from MLIR file\"\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return [], False, f\"MLIR file not found: {optimized_mlir_file}\"\n",
    "    except Exception as e:\n",
    "        return [], False, f\"Loop extraction error: {str(e)}\"\n",
    "\n",
    "def generate_futil_from_mlir(mlir_file: Path, futil_dir: Path) -> Tuple[Optional[Path], bool, Optional[str]]:\n",
    "    \"\"\"Generate FUTIL file from a single MLIR file - returns (futil_file, success, error_message)\"\"\"\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        futil_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        futil_path = futil_dir / f\"{mlir_file.stem}.futil\"\n",
    "        intermediate_mlir = futil_dir / f\"{mlir_file.stem}.mlir\"\n",
    "        \n",
    "        try:\n",
    "            # Step 1: hlstool command\n",
    "            hlstool_cmd = [\n",
    "                \"hlstool\",\n",
    "                \"--calyx-hw\",\n",
    "                \"--output-level=core\", \n",
    "                \"--ir\",\n",
    "                \"--allow-unregistered-dialects\",\n",
    "                str(mlir_file),\n",
    "                \"-o\", str(intermediate_mlir)\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(hlstool_cmd, capture_output=True, text=True, timeout=30)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                return None, False, f\"hlstool failed for {mlir_file.name}: {result.stderr}\"\n",
    "            \n",
    "            # Step 2: circt-translate command\n",
    "            translate_cmd = [\n",
    "                \"circt-translate\",\n",
    "                str(intermediate_mlir),\n",
    "                \"-o\", str(futil_path),\n",
    "                \"--export-calyx\"\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(translate_cmd, capture_output=True, text=True, timeout=60)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                return None, False, f\"circt-translate failed for {mlir_file.name}: {result.stderr}\"\n",
    "            \n",
    "            # Clean up intermediate file\n",
    "            intermediate_mlir.unlink(missing_ok=True)\n",
    "            \n",
    "            return futil_path, True, None\n",
    "            \n",
    "        except subprocess.TimeoutExpired:\n",
    "            return None, False, f\"Timeout processing {mlir_file.name}\"\n",
    "        except Exception as e:\n",
    "            return None, False, f\"Error processing {mlir_file.name}: {e}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return None, False, f\"FUTIL generation error: {str(e)}\"\n",
    "\n",
    "def generate_verilog_from_futil(futil_file: Path, verilog_dir: Path) -> Tuple[Optional[Path], bool, Optional[str]]:\n",
    "    \"\"\"Generate Verilog files from FUTIL - returns (verilog_file, success, error_message)\"\"\"\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        verilog_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        verilog_path = verilog_dir / f\"{futil_file.stem}.sv\"\n",
    "        \n",
    "        # Calyx compilation command\n",
    "        calyx_cmd = [\n",
    "            \"/home/kelvin/calyx/target/debug/calyx\",\n",
    "            \"-l\", \"/home/kelvin/calyx\",  # Add library path\n",
    "            \"-p\", \"fsm-opt\",\n",
    "            \"-x\", \"simplify-with-control:without-register\",\n",
    "            \"-x\", \"static-inline:offload-pause=false\", \n",
    "            \"-p\", \"lower\",\n",
    "            \"--nested\",\n",
    "            \"-d\", \"papercut\",\n",
    "            \"-d\", \"cell-share\",\n",
    "            \"-o\", str(verilog_path),\n",
    "            \"-b\", \"verilog\",\n",
    "            \"--synthesis\",\n",
    "            str(futil_file)\n",
    "        ]\n",
    "        \n",
    "        env = os.environ.copy()\n",
    "        result = subprocess.run(calyx_cmd, capture_output=True, text=True, timeout=300, cwd=str(CALYX_PATH), env=env)\n",
    "        \n",
    "        if result.returncode == 0 and verilog_path.exists():\n",
    "            return verilog_path, True, None\n",
    "        else:\n",
    "            error_msg = f\"Verilog generation failed: {result.stderr}\"\n",
    "            return None, False, error_msg\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return None, False, \"Verilog generation timed out\"\n",
    "    except Exception as e:\n",
    "        return None, False, f\"Verilog generation error: {str(e)}\"\n",
    "\n",
    "def run_synthesis(verilog_file: Path) -> SynthesisResult:\n",
    "    \"\"\"Run FABulous synthesis preprocessing only - returns SynthesisResult directly\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Run FABulous synthesis preprocessing (yosys + json generation)\n",
    "        synthesis_cmd = [\n",
    "            \"FABulous\", \"--debug\", str(FAB_PROJ_DIR), \"-p\",\n",
    "            \"load_fabric; gen_bitStream_spec; gen_cells_and_techmaps; \"\n",
    "            f\"gen_chipdb -routing_graph {FAB_PROJ_DIR}/.FABulous/routing_graph.dot -filter 5,1 5,2 5,3 5,4; \"\n",
    "            f\"synthesis_script {str(verilog_file)} -tcl {FAB_PROJ_DIR}/.FABulous/arch_synth.tcl;\"\n",
    "        ]\n",
    "        SYNTHESIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        synthesis_out = SYNTHESIS_OUTPUT_DIR / f\"{verilog_file.stem}_synth.json\"\n",
    "        p = os.environ.copy()\n",
    "        p[\"OUT_JSON_PATH\"] = str(synthesis_out)\n",
    "        p[\"TOP_MODULE\"] = verilog_file.stem\n",
    "        synthesis_result = subprocess.run(synthesis_cmd, capture_output=True, text=True, timeout=300, env=p)\n",
    "        synthesis_runtime = time.time() - start_time\n",
    "        \n",
    "        synthesis_success = synthesis_result.returncode == 0\n",
    "        error_message = synthesis_result.stderr if not synthesis_success else None\n",
    "\n",
    "        # Check for invalid synthesis cells\n",
    "        if synthesis_success and re.findall(r\"\\\"type\\\": \\\"(\\$.*?)\\\"\", synthesis_result.stdout):\n",
    "            r = re.findall(r\"\\\"type\\\": \\\"(\\$.*?)\\\"\", synthesis_result.stdout)\n",
    "            synthesis_success = False\n",
    "            error_message = f\"Invalid synthesis result, found cell: {set(r)}\"\n",
    "        \n",
    "        return SynthesisResult(\n",
    "            success=synthesis_success,\n",
    "            runtime=synthesis_runtime,\n",
    "            verilog_file=verilog_file,\n",
    "            synthesis_out_file=synthesis_out if synthesis_success else None,\n",
    "            error_message=error_message,\n",
    "            full_stdout=synthesis_result.stdout,\n",
    "            full_stderr=synthesis_result.stderr\n",
    "        )\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return SynthesisResult(\n",
    "            success=False,\n",
    "            runtime=time.time() - start_time,\n",
    "            verilog_file=verilog_file,\n",
    "            synthesis_out_file=None,\n",
    "            error_message=\"Synthesis timed out\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return SynthesisResult(\n",
    "            success=False,\n",
    "            runtime=time.time() - start_time,\n",
    "            verilog_file=verilog_file,\n",
    "            synthesis_out_file=None,\n",
    "            error_message=f\"Synthesis error: {str(e)}\"\n",
    "        )\n",
    "\n",
    "def run_parameter_sweep(synthesis_result: SynthesisResult, custom_params: dict = None) -> List[ParameterResult]:\n",
    "    \"\"\"Run NextPNR parameter sweep only - returns list of ParameterResult directly\"\"\"\n",
    "    if not synthesis_result.success or not synthesis_result.synthesis_out_file:\n",
    "        return []\n",
    "    \n",
    "    synthesis_json_path = Path(synthesis_result.synthesis_out_file)\n",
    "    \n",
    "    # Check if synthesis JSON exists\n",
    "    if not synthesis_json_path.exists():\n",
    "        return [ParameterResult(\n",
    "            config_id=0,\n",
    "            success=False,\n",
    "            runtime=0.0,\n",
    "            failure_type=FailureType.SYNTHESIS,\n",
    "            error_message=f\"Synthesis JSON not found: {synthesis_json_path}\"\n",
    "        )]\n",
    "    \n",
    "    PNR_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    out_json_path = PNR_OUTPUT_DIR / f\"{synthesis_json_path.stem}_pnr.json\"\n",
    "    out_fasm_path = PNR_OUTPUT_DIR / f\"{synthesis_json_path.stem}.fasm\"\n",
    "    parameter_results = []\n",
    "\n",
    "        # Use custom parameters or single default configuration\n",
    "    if custom_params:\n",
    "        conn_factor = custom_params.get('connectivity_factor', 0.0)\n",
    "        cong_factor = custom_params.get('congestion_factor', 0.0)\n",
    "        config_grid = [(conn_factor, cong_factor)]\n",
    "    else:\n",
    "        config_grid = grid  # Single default configuration\n",
    "    \n",
    "    for i, (conn_factor, cong_factor) in enumerate(config_grid):\n",
    "        param_start_time = time.time()\n",
    "        \n",
    "        # Run nextpnr with these parameters\n",
    "        try:\n",
    "            nextpnr_cmd = [\n",
    "                \"nextpnr-himbaechel\",\n",
    "                \"--chipdb\", str(CHIPDB_PATH),\n",
    "                \"--device\", \"FABulous\",\n",
    "                \"--json\", str(synthesis_json_path),\n",
    "                \"--write\", str(out_json_path),\n",
    "                \"-o\", f\"constrain-pair={CONSTRAIN_PAIR}\",\n",
    "                \"-o\", f\"fasm={out_fasm_path}\",  # Uncomment if FASM output needed\n",
    "                \"-o\", f\"fdc={FDC_PATH}\",\n",
    "                \"--placer-heap-seed-placement-strategy\", \"graph_grid\",\n",
    "                \"--placer-heap-beta\", str(BETA_VALUE),\n",
    "                \"--placer-heap-arch-connectivity-factor\", str(conn_factor),\n",
    "                \"--placer-heap-congestion-aware-factor\", str(cong_factor),\n",
    "                \"-o\", f\"placeTrial={PLACE_TRIALS}\",\n",
    "                \"--router1-timeout\", str(ROUTER_TIMEOUT)\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(nextpnr_cmd, capture_output=True, text=True, timeout=600)\n",
    "            param_runtime = time.time() - param_start_time\n",
    "            \n",
    "            param_success = result.returncode == 0\n",
    "            failure_type = FailureType.NONE if param_success else FailureType.ROUTING\n",
    "            \n",
    "            # Simple log analysis\n",
    "            placement_success = \"Final Placement\" in result.stdout\n",
    "            routing_failed = \"ERROR: Max iteration count reached\" in result.stdout\n",
    "            \n",
    "            if not param_success:\n",
    "                if not placement_success:\n",
    "                    failure_type = FailureType.PLACEMENT\n",
    "                elif routing_failed:\n",
    "                    failure_type = FailureType.ROUTING\n",
    "                else:\n",
    "                    failure_type = FailureType.UNKNOWN\n",
    "            \n",
    "            param_result = ParameterResult(\n",
    "                config_id=i,\n",
    "                success=param_success,\n",
    "                runtime=param_runtime,\n",
    "                parameters={'connectivity_factor': conn_factor, 'congestion_factor': cong_factor},\n",
    "                placement_info={'placement_success': placement_success},\n",
    "                routing_info={'routing_failed': routing_failed},\n",
    "                failure_type=failure_type,\n",
    "                full_stderr= result.stderr,\n",
    "                full_stdout=result.stdout,\n",
    "                error_message=result.stderr if not param_success else None\n",
    "            )\n",
    "            \n",
    "            parameter_results.append(param_result)\n",
    "            \n",
    "        except subprocess.TimeoutExpired:\n",
    "            param_runtime = time.time() - param_start_time\n",
    "            parameter_results.append(ParameterResult(\n",
    "                config_id=i,\n",
    "                success=False,\n",
    "                runtime=param_runtime,\n",
    "                parameters={'connectivity_factor': conn_factor, 'congestion_factor': cong_factor},\n",
    "                placement_info={},\n",
    "                routing_info={},\n",
    "                failure_type=FailureType.UNKNOWN,\n",
    "                error_message='Parameter run timed out'\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            param_runtime = time.time() - param_start_time\n",
    "            parameter_results.append(ParameterResult(\n",
    "                config_id=i,\n",
    "                success=False,\n",
    "                runtime=param_runtime,\n",
    "                parameters={'connectivity_factor': conn_factor, 'congestion_factor': cong_factor},\n",
    "                placement_info={},\n",
    "                routing_info={},\n",
    "                failure_type=FailureType.UNKNOWN,\n",
    "                error_message=str(e)\n",
    "            ))\n",
    "    \n",
    "    return parameter_results\n",
    "\n",
    "def run_complete_pipeline(mlir_file: Path) -> CompletePipelineResult:\n",
    "    \"\"\"\n",
    "    Run the complete MLIR to hardware pipeline:\n",
    "    MLIR -> Verilog -> Synthesis -> Parameter Sweep\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Ensure all stage directories exist\n",
    "    MLIR_OPTIMIZED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    MLIR_EXTRACTED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    FUTIL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    VERILOG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    SYNTHESIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    PNR_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Stage 1: Verilog Generation Pipeline\n",
    "    verilog_result = run_verilog_pipeline(mlir_file)\n",
    "    \n",
    "    # Stage 2: Synthesis (if Verilog generation succeeded)\n",
    "    synthesis_results = []\n",
    "    if verilog_result.success and verilog_result.verilog_files:\n",
    "        for verilog_file in verilog_result.verilog_files:\n",
    "            synthesis_results.append(run_synthesis(Path(verilog_file)))\n",
    "    \n",
    "    # Stage 3: Parameter Sweep (if any synthesis succeeded)\n",
    "    parameter_results = []\n",
    "    for synthesis_result in synthesis_results:\n",
    "        if synthesis_result.success:\n",
    "            parameter_results.extend(run_parameter_sweep(synthesis_result))\n",
    "\n",
    "    # Determine overall success and primary failure type\n",
    "    overall_success = False\n",
    "    primary_failure_type = FailureType.NONE\n",
    "    \n",
    "    if not verilog_result.success:\n",
    "        primary_failure_type = verilog_result.failure_stage or FailureType.VERILOG_GENERATION\n",
    "    elif not synthesis_results or not any(s.success for s in synthesis_results):\n",
    "        primary_failure_type = FailureType.SYNTHESIS\n",
    "    elif not parameter_results or not any(p.success for p in parameter_results):\n",
    "        # Find most common parameter failure type\n",
    "        if parameter_results:\n",
    "            failure_types = [p.failure_type for p in parameter_results if p.failure_type]\n",
    "            if failure_types:\n",
    "                primary_failure_type = max(set(failure_types), key=failure_types.count)\n",
    "            else:\n",
    "                primary_failure_type = FailureType.UNKNOWN\n",
    "        else:\n",
    "            primary_failure_type = FailureType.UNKNOWN\n",
    "    else:\n",
    "        overall_success = True\n",
    "        primary_failure_type = FailureType.NONE\n",
    "    \n",
    "    # Create and return complete result\n",
    "    return CompletePipelineResult(\n",
    "        source_file=mlir_file,\n",
    "        overall_success=overall_success,\n",
    "        total_runtime=time.time() - start_time,\n",
    "        verilog_pipeline=verilog_result,\n",
    "        synthesis_results=synthesis_results,\n",
    "        parameter_results=parameter_results,\n",
    "        primary_failure_type=primary_failure_type\n",
    "    )\n",
    "\n",
    "def process_mlir_benchmarks(mlir_files: List[Path]) -> List[CompletePipelineResult]:\n",
    "    \"\"\"Process multiple MLIR files through the complete pipeline\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Processing {len(mlir_files)} MLIR files through complete pipeline...\")\n",
    "    print(\"Stage directories:\")\n",
    "    print(f\"  01_optimized_mlir: {MLIR_OPTIMIZED_DIR}\")\n",
    "    print(f\"  02_extracted_mlir: {MLIR_EXTRACTED_DIR}\")\n",
    "    print(f\"  03_futil: {FUTIL_OUTPUT_DIR}\")\n",
    "    print(f\"  04_verilog: {VERILOG_OUTPUT_DIR}\")\n",
    "    print(f\"  05_synthesis: {SYNTHESIS_OUTPUT_DIR}\")\n",
    "    print(f\"  06_PNR: {PNR_OUTPUT_DIR}\")\n",
    "\n",
    "    for i, mlir_file in enumerate(mlir_files):\n",
    "        print(f\"\\n[{i+1}/{len(mlir_files)}] Processing: {Path(mlir_file).name}\")\n",
    "        \n",
    "        try:\n",
    "            result = run_complete_pipeline(mlir_file)\n",
    "            results.append(result)\n",
    "            \n",
    "            status = \"âœ“ SUCCESS\" if result.overall_success else f\"âœ— FAILED ({result.primary_failure_type.value})\"\n",
    "            print(f\"  Result: {status} | Runtime: {result.total_runtime:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            # Create failed result with proper structure\n",
    "            failed_verilog_result = VerilogPipelineResult(\n",
    "                source_file=mlir_file,\n",
    "                success=False,\n",
    "                runtime=0.0,\n",
    "                failure_stage=FailureType.UNKNOWN,\n",
    "                error_message=str(e)\n",
    "            )\n",
    "            \n",
    "            failed_result = CompletePipelineResult(\n",
    "                source_file=mlir_file,\n",
    "                overall_success=False,\n",
    "                total_runtime=0.0,\n",
    "                verilog_pipeline=failed_verilog_result,\n",
    "                synthesis_results=[],\n",
    "                parameter_results=[],\n",
    "                primary_failure_type=FailureType.UNKNOWN\n",
    "            )\n",
    "            results.append(failed_result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6838d7",
   "metadata": {},
   "source": [
    "## 7. Interactive Dashboard\n",
    "\n",
    "Interactive dashboard for exploring results across different Verilog files with combined analysis and file-specific views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thh4i34q6tg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b61655cb84240c480bac6573d5790af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ðŸ§ª Single MLIR File Pipeline Experiment</h3>'), HBox(children=(Dropdown(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Interactive Dashboard loaded successfully!\n",
      "ðŸ“ Select an MLIR file and click 'Run Pipeline' to start.\n",
      "ðŸ“„ File dropdown is now sorted alphabetically.\n",
      "ðŸ§¹ Clear button functionality has been fixed!\n"
     ]
    }
   ],
   "source": [
    "# Single MLIR File Pipeline Runner with Interactive Dashboard\n",
    "# Fixed widget system to prevent multiple executions\n",
    "\n",
    "def make_clickable_path(file_path: Path) -> str:\n",
    "    \"\"\"Convert a file path into a clickable terminal hyperlink using OSC 8 sequences\"\"\"\n",
    "    if not file_path:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to absolute path\n",
    "    abs_path = file_path.resolve()\n",
    "    \n",
    "    # Create OSC 8 hyperlink: \\033]8;;file://path\\033\\\\text\\033]8;;\\033\\\\\n",
    "    # This creates a clickable link in terminals that support OSC 8\n",
    "    return f\"file://{abs_path}\"\n",
    "\n",
    "def make_clickable_dir(dir_path: Path) -> str:\n",
    "    \"\"\"Convert a directory path into a clickable terminal hyperlink\"\"\"\n",
    "    if not dir_path:\n",
    "        return \"\"\n",
    "    \n",
    "    abs_path = dir_path.resolve()\n",
    "    return f\"file://{abs_path}\"\n",
    "\n",
    "def clean_log_content(log_content: str) -> str:\n",
    "    \"\"\"Remove ANSI escape codes, color codes, and other rich formatting from log content\"\"\"\n",
    "    import re\n",
    "    \n",
    "    if not log_content:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove ANSI escape sequences (colors, cursor movements, etc.)\n",
    "    # Pattern matches: ESC[ followed by any number of parameters and a final character\n",
    "    ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "    cleaned = ansi_escape.sub('', log_content)\n",
    "    \n",
    "    # Remove other common escape sequences\n",
    "    # Remove carriage returns that don't have newlines (progress indicators)\n",
    "    cleaned = re.sub(r'\\r(?!\\n)', '\\n', cleaned)\n",
    "    \n",
    "    # Remove excessive whitespace but preserve structure\n",
    "    cleaned = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', cleaned)\n",
    "    \n",
    "    # Remove common progress indicators and spinner characters\n",
    "    cleaned = re.sub(r'[â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â |\\-\\\\/]', '', cleaned)\n",
    "    \n",
    "    # Remove excessive spaces (more than 4 consecutive spaces become 4)\n",
    "    cleaned = re.sub(r' {5,}', '    ', cleaned)\n",
    "    \n",
    "    # Clean up any remaining control characters except tabs and newlines\n",
    "    cleaned = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', cleaned)\n",
    "    \n",
    "    # Remove lines that are just whitespace or repetitive characters\n",
    "    lines = cleaned.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        # Skip lines that are just repeated characters (like ===== or -----)\n",
    "        if line.strip() and not re.match(r'^[=\\-_*#]{10,}$', line.strip()):\n",
    "            cleaned_lines.append(line)\n",
    "        elif not line.strip():\n",
    "            # Keep empty lines but limit consecutive empty lines\n",
    "            if not (cleaned_lines and cleaned_lines[-1] == ''):\n",
    "                cleaned_lines.append(line)\n",
    "    \n",
    "    return '\\n'.join(cleaned_lines).strip()\n",
    "\n",
    "def display_scrollable_log(log_content: str, title: str, max_height: str = \"300px\"):\n",
    "    \"\"\"Display log content in a scrollable text area with rich formatting removed\"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    import html\n",
    "    \n",
    "    # Clean the log content first\n",
    "    cleaned_content = clean_log_content(log_content)\n",
    "    \n",
    "    # Add summary info if content was cleaned\n",
    "    original_lines = len(log_content.split('\\n')) if log_content else 0\n",
    "    cleaned_lines = len(cleaned_content.split('\\n')) if cleaned_content else 0\n",
    "    \n",
    "    # Escape HTML characters\n",
    "    escaped_content = html.escape(cleaned_content)\n",
    "    \n",
    "    # Add info about filtering if significant content was removed\n",
    "    filter_info = \"\"\n",
    "    if original_lines > cleaned_lines + 10:  # Significant filtering occurred\n",
    "        filter_info = f\"\"\"\n",
    "        <div style=\"font-size: 11px; color: #666; padding: 4px 8px; background-color: #f0f0f0; border-bottom: 1px solid #ddd;\">\n",
    "            ðŸ“‹ Log filtered: {original_lines} â†’ {cleaned_lines} lines (removed formatting/progress indicators)\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Create scrollable HTML\n",
    "    html_content = f\"\"\"\n",
    "    <div style=\"border: 1px solid #ccc; border-radius: 5px; margin: 10px 0;\">\n",
    "        <div style=\"background-color: #f5f5f5; padding: 8px; border-bottom: 1px solid #ccc; font-weight: bold;\">\n",
    "            {title}\n",
    "        </div>\n",
    "        {filter_info}\n",
    "        <div style=\"max-height: {max_height}; overflow-y: auto; padding: 10px; font-family: 'Courier New', monospace; font-size: 12px; background-color: #fafafa; line-height: 1.3;\">\n",
    "            <pre style=\"margin: 0; white-space: pre-wrap; word-wrap: break-word;\">{escaped_content}</pre>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html_content))\n",
    "\n",
    "\n",
    "def run_single_file_experiment(mlir_file_path: str, verbose: bool = True, \n",
    "                              custom_params: dict = None):\n",
    "    \"\"\"\n",
    "    Run the complete pipeline on a single MLIR file with detailed output for each stage.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mlir_file_path : str\n",
    "        Path to the MLIR file to process\n",
    "    verbose : bool\n",
    "        Whether to show detailed output for each stage\n",
    "    custom_params : dict\n",
    "        Custom parameter configuration for NextPNR sweep\n",
    "        Format: {'connectivity_factor': float, 'congestion_factor': float}\n",
    "        If None, uses a single default configuration (0.0, 0.0)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    CompletePipelineResult\n",
    "        Complete pipeline result with all stage information\n",
    "    \"\"\"\n",
    "    mlir_path = Path(mlir_file_path)\n",
    "    \n",
    "    if not mlir_path.exists():\n",
    "        print(f\"âŒ ERROR: MLIR file not found: {mlir_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ðŸš€ Starting Complete Pipeline Experiment\")\n",
    "    print(f\"ðŸ“ Input File: {make_clickable_path(mlir_path)}\")\n",
    "    print(f\"ðŸ“‚ Source Path: {make_clickable_path(mlir_path)}\")\n",
    "    print(f\"â° Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    if custom_params:\n",
    "        print(f\"ðŸŽ›ï¸  Custom Parameters: connectivity={custom_params.get('connectivity_factor', 'N/A')}, congestion={custom_params.get('congestion_factor', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"ðŸŽ›ï¸  Using Default Single Configuration: connectivity=0.0, congestion=0.0\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Run the complete pipeline\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Stage 1: Verilog Generation Pipeline\n",
    "    verilog_result = run_verilog_pipeline(mlir_path)\n",
    "    \n",
    "    # Stage 2: Synthesis (if Verilog generation succeeded)\n",
    "    synthesis_results = []\n",
    "    if verilog_result.success and verilog_result.verilog_files:\n",
    "        for verilog_file in verilog_result.verilog_files:\n",
    "            synthesis_results.append(run_synthesis(Path(verilog_file)))\n",
    "    \n",
    "    # Stage 3: Parameter Sweep (if any synthesis succeeded)\n",
    "    parameter_results = []\n",
    "    for synthesis_result in synthesis_results:\n",
    "        if synthesis_result.success:\n",
    "            parameter_results.extend(run_parameter_sweep(synthesis_result, custom_params))\n",
    "\n",
    "    # Determine overall success and primary failure type\n",
    "    overall_success = False\n",
    "    primary_failure_type = FailureType.NONE\n",
    "    \n",
    "    if not verilog_result.success:\n",
    "        primary_failure_type = verilog_result.failure_stage or FailureType.VERILOG_GENERATION\n",
    "    elif not synthesis_results or not any(s.success for s in synthesis_results):\n",
    "        primary_failure_type = FailureType.SYNTHESIS\n",
    "    elif not parameter_results or not any(p.success for p in parameter_results):\n",
    "        # Find most common parameter failure type\n",
    "        if parameter_results:\n",
    "            failure_types = [p.failure_type for p in parameter_results if p.failure_type]\n",
    "            if failure_types:\n",
    "                primary_failure_type = max(set(failure_types), key=failure_types.count)\n",
    "            else:\n",
    "                primary_failure_type = FailureType.UNKNOWN\n",
    "        else:\n",
    "            primary_failure_type = FailureType.UNKNOWN\n",
    "    else:\n",
    "        overall_success = True\n",
    "        primary_failure_type = FailureType.NONE\n",
    "    \n",
    "    # Create result object\n",
    "    result = CompletePipelineResult(\n",
    "        source_file=mlir_path,\n",
    "        overall_success=overall_success,\n",
    "        total_runtime=time.time() - start_time,\n",
    "        verilog_pipeline=verilog_result,\n",
    "        synthesis_results=synthesis_results,\n",
    "        parameter_results=parameter_results,\n",
    "        primary_failure_type=primary_failure_type\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Display detailed results\n",
    "    print(f\"\\nðŸ Pipeline Completed in {total_time:.2f}s\")\n",
    "    print(f\"ðŸ“Š Overall Success: {'âœ… PASS' if result.overall_success else 'âŒ FAIL'}\")\n",
    "    print(f\"ðŸŽ¯ Primary Failure: {result.primary_failure_type.value}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # === STAGE 1: VERILOG PIPELINE ===\n",
    "    print(\"\\nðŸ“‹ STAGE 1: VERILOG GENERATION PIPELINE\")\n",
    "    print(f\"â±ï¸  Total Stage Time: {result.verilog_pipeline.runtime:.2f}s\")\n",
    "    print(f\"âœ… Stage Success: {'PASS' if result.verilog_pipeline.success else 'FAIL'}\")\n",
    "    \n",
    "    if verbose:\n",
    "        vp = result.verilog_pipeline\n",
    "        print(\"\\n  ðŸ”§ Sub-Stage 1.1: MLIR Optimization\")\n",
    "        print(f\"     â±ï¸  Time: {vp.mlir_optimization_time:.2f}s\")\n",
    "        print(f\"     ðŸ“„ Input: {make_clickable_path(mlir_path)}\")\n",
    "        if vp.optimized_mlir_file:\n",
    "            print(f\"     ðŸ“„ Output: {make_clickable_path(vp.optimized_mlir_file)}\")\n",
    "        \n",
    "        print(\"\\n  ðŸ”„ Sub-Stage 1.2: Loop Extraction\")\n",
    "        print(f\"     â±ï¸  Time: {vp.loop_extraction_time:.2f}s\")\n",
    "        if vp.function_extracted is not None:\n",
    "            print(f\"     ðŸ“Š Extracted Files: {len(vp.function_extracted)}\")\n",
    "        if vp.function_extracted:\n",
    "            for i, func in enumerate(vp.function_extracted):\n",
    "                print(f\"     ðŸ“‚ Function {i+1}: {make_clickable_path(func)}\")\n",
    "        \n",
    "        print(\"\\n  âš™ï¸  Sub-Stage 1.3: FUTIL Generation\")\n",
    "        print(f\"     â±ï¸  Time: {vp.futil_generation_time:.2f}s\")\n",
    "        if vp.futil_files:\n",
    "            for i, futil in enumerate(vp.futil_files):\n",
    "                print(f\"     ðŸ“„ FUTIL File {i+1}: {make_clickable_path(futil)}\")\n",
    "        \n",
    "        print(\"\\n  ðŸ“¦ Final Verilog Output:\")\n",
    "        if vp.verilog_files:\n",
    "            print(f\"     ðŸ“Š Generated Files: {len(vp.verilog_files)}\")\n",
    "            for i, vf in enumerate(vp.verilog_files):\n",
    "                print(f\"       {i+1}. {make_clickable_path(vf)}\")\n",
    "        else:\n",
    "            print(\"     âŒ No Verilog files generated\")\n",
    "        \n",
    "        if not vp.success:\n",
    "            print(\"\\n  âŒ FAILURE DETAILS:\")\n",
    "            print(f\"     ðŸŽ¯ Failed Stage: {vp.failure_stage.value if vp.failure_stage else 'unknown'}\")\n",
    "            if vp.error_message:\n",
    "                print(f\"     ðŸ’¬ Error: {vp.error_message}\")\n",
    "    \n",
    "    # === STAGE 2: SYNTHESIS ===\n",
    "    print(\"\\nðŸ“‹ STAGE 2: SYNTHESIS (FABulous)\")\n",
    "    if result.synthesis_results:\n",
    "        successful_synthesis = sum(1 for s in result.synthesis_results if s.success)\n",
    "        total_synthesis_time = sum(s.runtime for s in result.synthesis_results)\n",
    "        print(f\"â±ï¸  Total Stage Time: {total_synthesis_time:.2f}s\")\n",
    "        print(f\"âœ… Stage Success: {successful_synthesis}/{len(result.synthesis_results)} operations successful\")\n",
    "        \n",
    "        if verbose:\n",
    "            for i, synth in enumerate(result.synthesis_results):\n",
    "                print(f\"\\n  ðŸ”¨ Synthesis Operation {i+1}:\")\n",
    "                print(f\"     âœ… Success: {'PASS' if synth.success else 'FAIL'}\")\n",
    "                print(f\"     â±ï¸  Runtime: {synth.runtime:.2f}s\")\n",
    "                if synth.verilog_file:\n",
    "                    print(f\"     ðŸ“„ Input Verilog: {make_clickable_path(synth.verilog_file)}\")\n",
    "                if synth.synthesis_out_file:\n",
    "                    print(f\"     ðŸ“„ Output JSON: {make_clickable_path(synth.synthesis_out_file)}\")\n",
    "                if synth.error_message:\n",
    "                    print(f\"     âŒ Error: {synth.error_message}\")\n",
    "                \n",
    "                # Display scrollable logs directly in output\n",
    "                if synth.full_stdout:\n",
    "                    print(f\"\\n     ðŸ“œ Synthesis {i+1} Output Log:\")\n",
    "                    display_scrollable_log(synth.full_stdout, f\"Synthesis {i+1} Output Log\", max_height=\"200px\")\n",
    "                    \n",
    "                if synth.full_stderr:\n",
    "                    print(f\"\\n     ðŸ“œ Synthesis {i+1} Error Log:\")\n",
    "                    display_scrollable_log(synth.full_stderr, f\"Synthesis {i+1} Error Log\", max_height=\"200px\")\n",
    "    else:\n",
    "        print(\"âŒ No synthesis operations performed\")\n",
    "\n",
    "    # === STAGE 3: PARAMETER SWEEP ===\n",
    "    print(\"\\nðŸ“‹ STAGE 3: PARAMETER SWEEP (NextPNR)\")\n",
    "    if result.parameter_results:\n",
    "        successful_params = sum(1 for p in result.parameter_results if p.success)\n",
    "        total_param_time = sum(p.runtime for p in result.parameter_results)\n",
    "        avg_param_time = total_param_time / len(result.parameter_results)\n",
    "        \n",
    "        print(f\"â±ï¸  Total Stage Time: {total_param_time:.2f}s\")\n",
    "        print(f\"â±ï¸  Average Config Time: {avg_param_time:.2f}s\")\n",
    "        print(f\"âœ… Stage Success: {successful_params}/{len(result.parameter_results)} configurations successful\")\n",
    "        print(f\"ðŸ“Š Success Rate: {successful_params/len(result.parameter_results)*100:.1f}%\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n  ðŸ“ˆ Parameter Configuration Results:\")\n",
    "            failure_types = {}\n",
    "            for param in result.parameter_results:\n",
    "                conn_factor = param.parameters.get('connectivity_factor', 'N/A')\n",
    "                cong_factor = param.parameters.get('congestion_factor', 'N/A')\n",
    "                \n",
    "                if param.success:\n",
    "                    print(f\"     âœ… Config {param.config_id}: conn={conn_factor}, cong={cong_factor}, time={param.runtime:.2f}s\")\n",
    "                else:\n",
    "                    failure_type = param.failure_type.value if param.failure_type else 'unknown'\n",
    "                    failure_types[failure_type] = failure_types.get(failure_type, 0) + 1\n",
    "                    print(f\"     âŒ Config {param.config_id}: conn={conn_factor}, cong={cong_factor}\")\n",
    "                    print(f\"        ðŸŽ¯ Failure: {failure_type}, Time: {param.runtime:.2f}s\")\n",
    "                    if param.error_message:\n",
    "                        error_preview = param.error_message[:100] + \"...\" if len(param.error_message) > 100 else param.error_message\n",
    "                        print(f\"        ðŸ’¬ Error: {error_preview}\")\n",
    "                \n",
    "                # Display scrollable logs directly in output for each config\n",
    "                if param.full_stdout:\n",
    "                    print(f\"\\n     ðŸ“œ NextPNR Config {param.config_id} Output Log:\")\n",
    "                    display_scrollable_log(param.full_stdout, f\"NextPNR Config {param.config_id} Output Log\", max_height=\"300px\")\n",
    "                    \n",
    "                if param.full_stderr:\n",
    "                    print(f\"\\n     ðŸ“œ NextPNR Config {param.config_id} Error Log:\")\n",
    "                    display_scrollable_log(param.full_stderr, f\"NextPNR Config {param.config_id} Error Log\", max_height=\"200px\")\n",
    "            \n",
    "            if failure_types:\n",
    "                print(\"\\n  âŒ Parameter Failure Summary:\")\n",
    "                for failure_type, count in failure_types.items():\n",
    "                    print(f\"     ðŸŽ¯ {failure_type}: {count} configurations\")\n",
    "    else:\n",
    "        print(\"âŒ No parameter sweep performed\")\n",
    "    \n",
    "    # === SUMMARY SECTION ===\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸ“Š EXPERIMENT SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ðŸ“ File: {make_clickable_path(mlir_path)}\")\n",
    "    print(f\"â° Total Runtime: {result.total_runtime:.2f}s\")\n",
    "    print(f\"ðŸŽ¯ Overall Result: {'ðŸŽ‰ SUCCESS' if result.overall_success else 'ðŸ’¥ FAILED'}\")\n",
    "    \n",
    "    if not result.overall_success:\n",
    "        print(f\"âŒ Primary Failure: {result.primary_failure_type.value}\")\n",
    "    \n",
    "    # Performance breakdown\n",
    "    print(\"\\nâ±ï¸  Stage Performance Breakdown:\")\n",
    "    print(f\"   Verilog Pipeline:  {result.verilog_pipeline.runtime:6.2f}s ({result.verilog_pipeline.runtime/result.total_runtime*100:4.1f}%)\")\n",
    "    if result.synthesis_results:\n",
    "        synth_time = sum(s.runtime for s in result.synthesis_results)\n",
    "        print(f\"   Synthesis:         {synth_time:6.2f}s ({synth_time/result.total_runtime*100:4.1f}%)\")\n",
    "    if result.parameter_results:\n",
    "        param_time = sum(p.runtime for p in result.parameter_results)\n",
    "        print(f\"   Parameter Sweep:   {param_time:6.2f}s ({param_time/result.total_runtime*100:4.1f}%)\")\n",
    "    \n",
    "    # Resource utilization\n",
    "    print(\"\\nðŸ“¦ Resource Utilization:\")\n",
    "    if result.verilog_pipeline.verilog_files:\n",
    "        print(f\"   Verilog Files Generated: {len(result.verilog_pipeline.verilog_files)}\")\n",
    "    if result.synthesis_results:\n",
    "        print(f\"   Synthesis Operations: {len(result.synthesis_results)}\")\n",
    "    if result.parameter_results:\n",
    "        print(f\"   Parameter Configurations: {len(result.parameter_results)}\")\n",
    "    \n",
    "    # Stage directories info with clickable links\n",
    "    print(\"\\nðŸ“‚ Output Files Located In:\")\n",
    "    print(f\"   MLIR Optimized:    {make_clickable_dir(MLIR_OPTIMIZED_DIR)}\")\n",
    "    print(f\"   MLIR Extracted:    {make_clickable_dir(MLIR_EXTRACTED_DIR)}\")\n",
    "    print(f\"   FUTIL Files:       {make_clickable_dir(FUTIL_OUTPUT_DIR)}\")\n",
    "    print(f\"   Verilog Files:     {make_clickable_dir(VERILOG_OUTPUT_DIR)}\")\n",
    "    print(f\"   Synthesis Results: {make_clickable_dir(SYNTHESIS_OUTPUT_DIR)}\")\n",
    "    print(f\"   PnR Results:       {make_clickable_dir(PNR_OUTPUT_DIR)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ Experiment completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# PROPER WIDGET SYSTEM with execution control\n",
    "class ExperimentController:\n",
    "    \"\"\"Controller class to manage experiment execution and prevent multiple runs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.is_running = False\n",
    "        self.widgets = {}\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        \"\"\"Create all widgets fresh\"\"\"\n",
    "        # Get available MLIR files\n",
    "        available_files = list(Path(BENCHMARK_ROOT_DIR).glob(\"*.mlir\"))\n",
    "        if not available_files:\n",
    "            print(f\"âŒ No MLIR files found in {BENCHMARK_ROOT_DIR}\")\n",
    "            return None\n",
    "            \n",
    "        # Sort files alphabetically by name (case-insensitive)\n",
    "        available_files.sort(key=lambda f: f.name.lower())\n",
    "        file_options = [(f.name, str(f)) for f in available_files]\n",
    "        \n",
    "        # Create widgets\n",
    "        self.widgets['file_selector'] = widgets.Dropdown(\n",
    "            options=file_options,\n",
    "            description='MLIR File:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.widgets['verbose_checkbox'] = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Show detailed output',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.widgets['use_grid_checkbox'] = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Use grid',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.widgets['connectivity_slider'] = widgets.FloatSlider(\n",
    "            value=0.0,\n",
    "            min=0.0,\n",
    "            max=2.0,\n",
    "            step=0.1,\n",
    "            description='Connectivity:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.widgets['congestion_slider'] = widgets.FloatSlider(\n",
    "            value=0.0,\n",
    "            min=0.0,\n",
    "            max=2.0,\n",
    "            step=0.1,\n",
    "            description='Congestion:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px'),\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.widgets['run_button'] = widgets.Button(\n",
    "            description='ðŸš€ Run Pipeline',\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.widgets['clear_button'] = widgets.Button(\n",
    "            description='ðŸ§¹ Clear Output',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.widgets['output_area'] = widgets.Output()\n",
    "        \n",
    "        # Set up interactions\n",
    "        self.widgets['use_grid_checkbox'].observe(self._toggle_custom_params, names='value')\n",
    "        self.widgets['run_button'].on_click(self._on_run_button_click)\n",
    "        self.widgets['clear_button'].on_click(self._on_clear_button_click)\n",
    "        \n",
    "        return self._create_layout()\n",
    "    \n",
    "    def _toggle_custom_params(self, change):\n",
    "        \"\"\"Toggle custom parameter sliders\"\"\"\n",
    "        # enabled = change['new']\n",
    "        self.widgets['connectivity_slider'].disabled = change['new']\n",
    "        self.widgets['congestion_slider'].disabled = change['new']\n",
    "    \n",
    "    def _on_run_button_click(self, button):\n",
    "        \"\"\"Handle run button click with execution control\"\"\"\n",
    "        if self.is_running:\n",
    "            with self.widgets['output_area']:\n",
    "                print(\"âš ï¸ Experiment already running! Please wait for completion.\")\n",
    "            return\n",
    "        \n",
    "        self.is_running = True\n",
    "        button.disabled = True\n",
    "        button.description = 'â³ Running...'\n",
    "        \n",
    "        try:\n",
    "            with self.widgets['output_area']:\n",
    "                self.widgets['output_area'].clear_output(wait=True)\n",
    "                \n",
    "                # Get parameters\n",
    "                selected_file = self.widgets['file_selector'].value\n",
    "                verbose = self.widgets['verbose_checkbox'].value\n",
    "                use_grid_params = self.widgets['use_grid_checkbox'].value\n",
    "                \n",
    "                custom_params = None\n",
    "                if not use_grid_params:\n",
    "                    custom_params = {\n",
    "                        'connectivity_factor': self.widgets['connectivity_slider'].value,\n",
    "                        'congestion_factor': self.widgets['congestion_slider'].value\n",
    "                    }\n",
    "                \n",
    "                # Run experiment\n",
    "                try:\n",
    "                    result = run_single_file_experiment(selected_file, verbose, custom_params)\n",
    "                    if result:\n",
    "                        print(\"\\nâœ… Experiment completed successfully!\")\n",
    "                    else:\n",
    "                        print(\"\\nâŒ Experiment failed to start!\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"\\nðŸ’¥ Experiment crashed with error: {str(e)}\")\n",
    "                    import traceback\n",
    "                    print(\"Full traceback:\")\n",
    "                    print(traceback.format_exc())\n",
    "        finally:\n",
    "            # Always reset state\n",
    "            self.is_running = False\n",
    "            button.disabled = False\n",
    "            button.description = 'ðŸš€ Run Pipeline'\n",
    "    \n",
    "    def _on_clear_button_click(self, button):\n",
    "        \"\"\"Handle clear button click - fixed version\"\"\"\n",
    "        with self.widgets['output_area']:\n",
    "            # Use clear_output without the context manager to ensure it works\n",
    "            clear_output(wait=False)\n",
    "            print(\"ðŸ§¹ Output cleared successfully!\")\n",
    "    \n",
    "    def _create_layout(self):\n",
    "        \"\"\"Create the widget layout\"\"\"\n",
    "        main_controls = widgets.HBox([\n",
    "            self.widgets['file_selector'],\n",
    "            self.widgets['verbose_checkbox'],\n",
    "            self.widgets['run_button'],\n",
    "            self.widgets['clear_button']\n",
    "        ])\n",
    "        \n",
    "        param_controls = widgets.VBox([\n",
    "            self.widgets['use_grid_checkbox'],\n",
    "            widgets.HBox([\n",
    "                self.widgets['connectivity_slider'], \n",
    "                self.widgets['congestion_slider']\n",
    "            ])\n",
    "        ])\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ðŸ§ª Single MLIR File Pipeline Experiment</h3>\"),\n",
    "            main_controls,\n",
    "            widgets.HTML(\"<h4>ðŸŽ›ï¸ Parameter Configuration</h4>\"),\n",
    "            param_controls,\n",
    "            widgets.HTML(\"<h4>ðŸ“‹ Results</h4>\"),\n",
    "            self.widgets['output_area']\n",
    "        ])\n",
    "\n",
    "# CREATE AND DISPLAY THE DASHBOARD\n",
    "try:\n",
    "    # Clean up any existing global controller\n",
    "    if 'experiment_controller' in globals():\n",
    "        del experiment_controller\n",
    "    \n",
    "    # Import clear_output for the clear button fix\n",
    "    from IPython.display import clear_output\n",
    "    \n",
    "    # Create new controller and display dashboard\n",
    "    experiment_controller = ExperimentController()\n",
    "    dashboard = experiment_controller.create_widgets()\n",
    "    \n",
    "    if dashboard:\n",
    "        display(dashboard)\n",
    "        print(\"âœ… Interactive Dashboard loaded successfully!\")\n",
    "        print(\"ðŸ“ Select an MLIR file and click 'Run Pipeline' to start.\")\n",
    "        print(\"ðŸ“„ File dropdown is now sorted alphabetically.\")\n",
    "        print(\"ðŸ§¹ Clear button functionality has been fixed!\")\n",
    "    else:\n",
    "        print(\"âŒ Failed to create dashboard - no MLIR files found or other error.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Dashboard creation failed: {str(e)}\")\n",
    "    import traceback\n",
    "    print(\"Full error:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bea2f4",
   "metadata": {},
   "source": [
    "## 3. NextPNR Execution and Analysis Functions\n",
    "\n",
    "Define functions to run FABulous preprocessing and nextpnr-himbaechel with comprehensive error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "384eec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13 MLIR files through complete pipeline...\n",
      "Stage directories:\n",
      "  01_optimized_mlir: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir\n",
      "  02_extracted_mlir: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir\n",
      "  03_futil: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/03_futil\n",
      "  04_verilog: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/04_verilog\n",
      "  05_synthesis: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/05_synthesis\n",
      "  06_PNR: /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/06_PNR\n",
      "\n",
      "[1/13] Processing: nw_nw.mlir\n",
      "Read 10429 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/nw_nw.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 1\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.19s\n",
      "\n",
      "[2/13] Processing: gemm_ncubed.mlir\n",
      "Read 1659 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/gemm_ncubed.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 7\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.05s\n",
      "\n",
      "[3/13] Processing: sort_radix.mlir\n",
      "Read 17429 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/sort_radix.mlir\n",
      "Successfully parsed with xDSL! Module has 7 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 0\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.14s\n",
      "\n",
      "[4/13] Processing: fft_transpose.mlir\n",
      "Read 79044 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/fft_transpose.mlir\n",
      "Successfully parsed with xDSL! Module has 3 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 439\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 1.82s\n",
      "\n",
      "[5/13] Processing: kmp_kmp.mlir\n",
      "Read 7632 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/kmp_kmp.mlir\n",
      "Successfully parsed with xDSL! Module has 2 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 2\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.08s\n",
      "\n",
      "[6/13] Processing: spmv_crs.mlir\n",
      "Read 1844 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/spmv_crs.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 7\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.05s\n",
      "\n",
      "[7/13] Processing: gemm_blocked.mlir\n",
      "Read 2341 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/gemm_blocked.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 6\n",
      "Replaced 2 float operations with integer operations in the module\n",
      "Found 0 scf.while loops to normalize\n",
      "Found function: gemm_blocked\n",
      "  Found 1 innermost loops\n",
      "  Replaced loop body of affine.for with call to gemm_blocked_inner_loop_0\n",
      "  Applying type replacement to extracted function gemm_blocked_inner_loop_0\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/gemm_blocked_inner_loop_0.mlir\n",
      "Total extracted functions: 1\n",
      "  Result: âœ— FAILED (futil_generation) | Runtime: 0.11s\n",
      "\n",
      "[8/13] Processing: fft_strided.mlir\n",
      "Read 4165 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/fft_strided.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 19\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.06s\n",
      "\n",
      "[9/13] Processing: md_knn.mlir\n",
      "Read 4335 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/md_knn.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 35\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.06s\n",
      "\n",
      "[10/13] Processing: spmv_ellpack.mlir\n",
      "Read 1659 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/spmv_ellpack.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 7\n",
      "Replaced 2 float operations with integer operations in the module\n",
      "Found 0 scf.while loops to normalize\n",
      "Found function: spmv_ellpack\n",
      "  Found 1 innermost loops\n",
      "  Replaced loop body of affine.for with call to spmv_ellpack_inner_loop_0\n",
      "  Applying type replacement to extracted function spmv_ellpack_inner_loop_0\n",
      "Total types replaced: 1\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/spmv_ellpack_inner_loop_0.mlir\n",
      "Total extracted functions: 1\n",
      "  Result: âœ— FAILED (futil_generation) | Runtime: 0.11s\n",
      "\n",
      "[11/13] Processing: stencil_stencil3d.mlir\n",
      "Read 6455 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/stencil_stencil3d.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "Found 0 scf.while loops to normalize\n",
      "Found function: stencil_stencil3d\n",
      "  Found 4 innermost loops\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_0\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_1\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_2\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_3\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_0\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_0.mlir\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_1\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_1.mlir\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_2\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_2.mlir\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_3\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_3.mlir\n",
      "Total extracted functions: 4\n",
      "  Result: âœ— FAILED (futil_generation) | Runtime: 0.27s\n",
      "\n",
      "[12/13] Processing: bfs_queue.mlir\n",
      "Read 6045 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/bfs_queue.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 28\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.08s\n",
      "\n",
      "[13/13] Processing: stencil_stencil2d.mlir\n",
      "Read 2134 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/stencil_stencil2d.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 0\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "  Result: âœ— FAILED (loop_extraction) | Runtime: 0.05s\n",
      "\n",
      "=== Complete Pipeline Results ===\n",
      "Total files processed: 13\n",
      "Successfully completed full pipeline: 0/13\n",
      "Verilog generation success: 0/13\n",
      "Synthesis success: 0/13\n",
      "Parameter sweep success: 0/13\n",
      "\n",
      "--- nw_nw.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.19s\n",
      "  Verilog Pipeline: âœ— (0.19s)\n",
      "    MLIR Opt: 0.09s\n",
      "    Loop Extract: 0.10s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- gemm_ncubed.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.05s\n",
      "  Verilog Pipeline: âœ— (0.05s)\n",
      "    MLIR Opt: 0.04s\n",
      "    Loop Extract: 0.00s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- sort_radix.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.14s\n",
      "  Verilog Pipeline: âœ— (0.14s)\n",
      "    MLIR Opt: 0.11s\n",
      "    Loop Extract: 0.02s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- fft_transpose.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 1.82s\n",
      "  Verilog Pipeline: âœ— (1.82s)\n",
      "    MLIR Opt: 1.72s\n",
      "    Loop Extract: 0.10s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- kmp_kmp.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.08s\n",
      "  Verilog Pipeline: âœ— (0.08s)\n",
      "    MLIR Opt: 0.06s\n",
      "    Loop Extract: 0.01s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- spmv_crs.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.05s\n",
      "  Verilog Pipeline: âœ— (0.05s)\n",
      "    MLIR Opt: 0.04s\n",
      "    Loop Extract: 0.00s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- gemm_blocked.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: futil_generation\n",
      "Total runtime: 0.11s\n",
      "  Verilog Pipeline: âœ— (0.11s)\n",
      "    MLIR Opt: 0.04s\n",
      "    Loop Extract: 0.04s\n",
      "    FUTIL Gen: 0.02s\n",
      "    function extracted: [PosixPath('/home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/gemm_blocked_inner_loop_0.mlir')]\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- fft_strided.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.06s\n",
      "  Verilog Pipeline: âœ— (0.06s)\n",
      "    MLIR Opt: 0.05s\n",
      "    Loop Extract: 0.01s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- md_knn.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.06s\n",
      "  Verilog Pipeline: âœ— (0.06s)\n",
      "    MLIR Opt: 0.05s\n",
      "    Loop Extract: 0.01s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- spmv_ellpack.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: futil_generation\n",
      "Total runtime: 0.11s\n",
      "  Verilog Pipeline: âœ— (0.11s)\n",
      "    MLIR Opt: 0.05s\n",
      "    Loop Extract: 0.04s\n",
      "    FUTIL Gen: 0.02s\n",
      "    function extracted: [PosixPath('/home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/spmv_ellpack_inner_loop_0.mlir')]\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- stencil_stencil3d.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: futil_generation\n",
      "Total runtime: 0.27s\n",
      "  Verilog Pipeline: âœ— (0.27s)\n",
      "    MLIR Opt: 0.08s\n",
      "    Loop Extract: 0.17s\n",
      "    FUTIL Gen: 0.03s\n",
      "    function extracted: [PosixPath('/home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_0.mlir'), PosixPath('/home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_1.mlir'), PosixPath('/home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_2.mlir'), PosixPath('/home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_3.mlir')]\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- bfs_queue.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.08s\n",
      "  Verilog Pipeline: âœ— (0.08s)\n",
      "    MLIR Opt: 0.06s\n",
      "    Loop Extract: 0.01s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n",
      "\n",
      "--- stencil_stencil2d.mlir ---\n",
      "Overall success: False\n",
      "Primary failure: loop_extraction\n",
      "Total runtime: 0.05s\n",
      "  Verilog Pipeline: âœ— (0.05s)\n",
      "    MLIR Opt: 0.05s\n",
      "    Loop Extract: 0.00s\n",
      "    FUTIL Gen: 0.00s\n",
      "    function extracted: []\n",
      "  Synthesis: No synthesis attempted\n"
     ]
    }
   ],
   "source": [
    "# Main execution with unified pipeline\n",
    "mlir_files = list(Path(BENCHMARK_ROOT_DIR).glob(\"*.mlir\"))\n",
    "\n",
    "# Run complete pipeline for all MLIR files\n",
    "complete_results = process_mlir_benchmarks(mlir_files)\n",
    "\n",
    "print(f\"\\n=== Complete Pipeline Results ===\")\n",
    "print(f\"Total files processed: {len(complete_results)}\")\n",
    "\n",
    "# Display summary statistics\n",
    "successful_complete = sum(1 for r in complete_results if r.overall_success)\n",
    "print(f\"Successfully completed full pipeline: {successful_complete}/{len(complete_results)}\")\n",
    "\n",
    "# Stage-wise success rates\n",
    "verilog_success = sum(1 for r in complete_results if r.verilog_pipeline.success)\n",
    "synthesis_success = sum(1 for r in complete_results if any(s.success for s in r.synthesis_results))\n",
    "pnr_success = sum(1 for r in complete_results if any(p.success for p in r.parameter_results))\n",
    "\n",
    "print(f\"Verilog generation success: {verilog_success}/{len(complete_results)}\")\n",
    "print(f\"Synthesis success: {synthesis_success}/{len(complete_results)}\")\n",
    "print(f\"Parameter sweep success: {pnr_success}/{len(complete_results)}\")\n",
    "\n",
    "# Display detailed results for each file\n",
    "for result in complete_results:\n",
    "    print(f\"\\n--- {os.path.basename(result.source_file)} ---\")\n",
    "    print(f\"Overall success: {result.overall_success}\")\n",
    "    print(f\"Primary failure: {result.primary_failure_type.value}\")\n",
    "    print(f\"Total runtime: {result.total_runtime:.2f}s\")\n",
    "    \n",
    "    # Stage details\n",
    "    vp = result.verilog_pipeline\n",
    "    print(f\"  Verilog Pipeline: {'âœ“' if vp.success else 'âœ—'} ({vp.runtime:.2f}s)\")\n",
    "    print(f\"    MLIR Opt: {vp.mlir_optimization_time:.2f}s\")\n",
    "    print(f\"    Loop Extract: {vp.loop_extraction_time:.2f}s\") \n",
    "    print(f\"    FUTIL Gen: {vp.futil_generation_time:.2f}s\")\n",
    "    print(f\"    function extracted: {vp.function_extracted}\")\n",
    "    \n",
    "    # Synthesis results (now multiple)\n",
    "    if result.synthesis_results:\n",
    "        successful_synthesis = sum(1 for s in result.synthesis_results if s.success)\n",
    "        total_synthesis_time = sum(s.runtime for s in result.synthesis_results)\n",
    "        print(f\"  Synthesis: {successful_synthesis}/{len(result.synthesis_results)} successful ({total_synthesis_time:.2f}s total)\")\n",
    "        \n",
    "        # Show details for failed synthesis\n",
    "        for i, synth in enumerate(result.synthesis_results):\n",
    "            if not synth.success:\n",
    "                print(f\"    Failed synthesis {i+1}: {synth.error_message}\")\n",
    "    else:\n",
    "        print(\"  Synthesis: No synthesis attempted\")\n",
    "    \n",
    "    if result.parameter_results:\n",
    "        successful_params = sum(1 for p in result.parameter_results if p.success)\n",
    "        print(f\"  Parameter sweep: {successful_params}/{len(result.parameter_results)} configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1755eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Auto-running dashboard components imported successfully!\n",
      "ðŸŽ¯ This dashboard will automatically run all benchmarks when called\n",
      "ðŸ“Š Provides summary page + dropdown for individual failure analysis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import auto-running dashboard components\n",
    "from simple_dashboard import create_auto_dashboard, SimpleResultsManager, SimpleBatchRunner, SimpleOverviewDashboard\n",
    "\n",
    "print(\"âœ… Auto-running dashboard components imported successfully!\")\n",
    "print(\"ðŸŽ¯ This dashboard will automatically run all benchmarks when called\")\n",
    "print(\"ðŸ“Š Provides summary page + dropdown for individual failure analysis\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78687054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ›ï¸ Setting up Auto-Running Dashboard System...\n",
      "ðŸš€ This dashboard will run ALL benchmarks automatically when called\n",
      "ðŸ“Š Shows summary + individual failure analysis\n",
      "\n",
      "ðŸ“Š Simple Results Manager Initialized (Current Runs Only)\n",
      "ðŸš€ Ready for new benchmark runs\n",
      "ðŸƒ Simple Batch Runner initialized\n",
      "ðŸ“ Benchmark directory: /home/kelvin/FABulous_fork/myProject/PnR/mlir\n",
      "ðŸ“Š Auto-Running Overview Dashboard initialized\n",
      "âœ… Auto-running dashboard system created!\n",
      "\n",
      "ðŸš€ Available components:\n",
      "   â€¢ results_manager - Manages current run results\n",
      "   â€¢ batch_runner - Run multiple benchmarks\n",
      "   â€¢ auto_dashboard - Auto-run all benchmarks with summary and failure analysis\n",
      "\n",
      "ðŸ“‹ Quick commands:\n",
      "   auto_dashboard.create_dashboard()     # Auto-run all benchmarks and show dashboard\n",
      "   auto_dashboard.create_dashboard(auto_run=False)  # Just show dashboard without auto-run\n",
      "   batch_runner.get_available_files()   # List MLIR files\n",
      "\n",
      "ðŸŽ¯ Ready-to-use dashboard:\n",
      "   â€¢ auto_dashboard - Auto-run all benchmarks with summary and failure dropdown\n",
      "   â€¢ results_manager - Manage current benchmark results\n",
      "   â€¢ batch_runner - Execute multiple MLIR files manually\n",
      "\n",
      "ðŸš€ Ready! The next cell will auto-run all benchmarks and show the dashboard.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Auto-Running Dashboard System\n",
    "\n",
    "print(\"ðŸŽ›ï¸ Setting up Auto-Running Dashboard System...\")\n",
    "print(\"ðŸš€ This dashboard will run ALL benchmarks automatically when called\")\n",
    "print(\"ðŸ“Š Shows summary + individual failure analysis\")\n",
    "print()\n",
    "\n",
    "# Create dashboard components\n",
    "results_manager, batch_runner, auto_dashboard = create_auto_dashboard()\n",
    "\n",
    "print(\"ðŸŽ¯ Ready-to-use dashboard:\")\n",
    "print(\"   â€¢ auto_dashboard - Auto-run all benchmarks with summary and failure dropdown\")\n",
    "print(\"   â€¢ results_manager - Manage current benchmark results\")\n",
    "print(\"   â€¢ batch_runner - Execute multiple MLIR files manually\")\n",
    "print()\n",
    "print(\"ðŸš€ Ready! The next cell will auto-run all benchmarks and show the dashboard.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "887c879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ›ï¸ STARTING AUTO-RUNNING DASHBOARD\n",
      "============================================================\n",
      "ðŸš€ This will automatically run ALL benchmarks and show results\n",
      "ðŸ“Š Summary page shows overall statistics\n",
      "ðŸ” Dropdown shows individual benchmark failures and stages\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ Launching auto-dashboard (this will run all MLIR files)...\n",
      "ðŸš€ Auto-starting all benchmark runs...\n",
      "ðŸ§¹ Cleared all current results\n",
      "ðŸš€ Starting batch run on 13 files\n",
      "  [1/13] Processing nw_nw.mlir\n",
      "Read 10429 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/nw_nw.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 1\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for nw_nw.mlir\n",
      "  [2/13] Processing gemm_ncubed.mlir\n",
      "Read 1659 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/gemm_ncubed.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 7\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for gemm_ncubed.mlir\n",
      "  [3/13] Processing sort_radix.mlir\n",
      "Read 17429 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/sort_radix.mlir\n",
      "Successfully parsed with xDSL! Module has 7 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 0\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for sort_radix.mlir\n",
      "  [4/13] Processing fft_transpose.mlir\n",
      "Read 79044 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/fft_transpose.mlir\n",
      "Successfully parsed with xDSL! Module has 3 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 439\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for fft_transpose.mlir\n",
      "  [5/13] Processing kmp_kmp.mlir\n",
      "Read 7632 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/kmp_kmp.mlir\n",
      "Successfully parsed with xDSL! Module has 2 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 2\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for kmp_kmp.mlir\n",
      "  [6/13] Processing spmv_crs.mlir\n",
      "Read 1844 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/spmv_crs.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 7\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for spmv_crs.mlir\n",
      "  [7/13] Processing gemm_blocked.mlir\n",
      "Read 2341 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/gemm_blocked.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 6\n",
      "Replaced 2 float operations with integer operations in the module\n",
      "Found 0 scf.while loops to normalize\n",
      "Found function: gemm_blocked\n",
      "  Found 1 innermost loops\n",
      "  Replaced loop body of affine.for with call to gemm_blocked_inner_loop_0\n",
      "  Applying type replacement to extracted function gemm_blocked_inner_loop_0\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/gemm_blocked_inner_loop_0.mlir\n",
      "Total extracted functions: 1\n",
      "âœ… Added result for gemm_blocked.mlir\n",
      "  [8/13] Processing fft_strided.mlir\n",
      "Read 4165 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/fft_strided.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 19\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for fft_strided.mlir\n",
      "  [9/13] Processing md_knn.mlir\n",
      "Read 4335 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/md_knn.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 35\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for md_knn.mlir\n",
      "  [10/13] Processing spmv_ellpack.mlir\n",
      "Read 1659 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/spmv_ellpack.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 7\n",
      "Replaced 2 float operations with integer operations in the module\n",
      "Found 0 scf.while loops to normalize\n",
      "Found function: spmv_ellpack\n",
      "  Found 1 innermost loops\n",
      "  Replaced loop body of affine.for with call to spmv_ellpack_inner_loop_0\n",
      "  Applying type replacement to extracted function spmv_ellpack_inner_loop_0\n",
      "Total types replaced: 1\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/spmv_ellpack_inner_loop_0.mlir\n",
      "Total extracted functions: 1\n",
      "âœ… Added result for spmv_ellpack.mlir\n",
      "  [11/13] Processing stencil_stencil3d.mlir\n",
      "Read 6455 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/stencil_stencil3d.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "Found 0 scf.while loops to normalize\n",
      "Found function: stencil_stencil3d\n",
      "  Found 4 innermost loops\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_0\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_1\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_2\n",
      "  Replaced loop body of affine.for with call to stencil_stencil3d_inner_loop_3\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_0\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_0.mlir\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_1\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_1.mlir\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_2\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_2.mlir\n",
      "  Applying type replacement to extracted function stencil_stencil3d_inner_loop_3\n",
      "Total types replaced: 0\n",
      "Replaced 0 float operations with integer operations in the module\n",
      "  Extracted function written to /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/02_extracted_mlir/stencil_stencil3d_inner_loop_3.mlir\n",
      "Total extracted functions: 4\n",
      "âœ… Added result for stencil_stencil3d.mlir\n",
      "  [12/13] Processing bfs_queue.mlir\n",
      "Read 6045 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/bfs_queue.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 28\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for bfs_queue.mlir\n",
      "  [13/13] Processing stencil_stencil2d.mlir\n",
      "Read 2134 characters from /home/kelvin/FABulous_fork/myProject/PnR/compilation_result/01_optimized_mlir/stencil_stencil2d.mlir\n",
      "Successfully parsed with xDSL! Module has 1 operations\n",
      "Replacing i64/f64 types with i32/f32 types...\n",
      "Total types replaced: 0\n",
      "Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 1249, in process_mlir_file\n",
      "    replace_types_i64_f64_to_i32(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 111, in replace_types_i64_f64_to_i32\n",
      "    replace_floatOp_to_intOp(module)\n",
      "  File \"/home/kelvin/FABulous_fork/myProject/PnR/inner_loop_to_func.py\", line 144, in replace_floatOp_to_intOp\n",
      "    new_op = arith.ConstantOp(value=int(op.operands[0]), value_type=builtin.i32)\n",
      "                                        ~~~~~~~~~~~^^^\n",
      "  File \"/home/kelvin/FABulous_fork/.venv/lib/python3.12/site-packages/xdsl/ir/core.py\", line 755, in __getitem__\n",
      "    return self._op._operands[idx]  # pyright: ignore[reportPrivateUsage]\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^\n",
      "IndexError: tuple index out of range\n",
      "\n",
      "âœ… Added result for stencil_stencil2d.mlir\n",
      "âœ… Batch run completed! 13 files processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca17ed660dd43409ea589028346053e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>ðŸŽ›ï¸ Benchmark Dashboard - Auto Runner</h2>'), HBox(children=(Button(button_styleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "ðŸŽ® Dashboard Features:\n",
      "   ðŸ“Š Summary section shows total runs, success rate, runtime stats\n",
      "   ðŸ“ˆ Charts show success distribution and runtime histogram\n",
      "   ðŸ” Failure dropdown lists all failed benchmarks with failure stage\n",
      "   ðŸ“‹ Select a failed benchmark to see detailed error analysis\n",
      "   ðŸ”„ Refresh button updates results, Clear button resets\n",
      "   ðŸš€ Run All button re-runs all benchmarks\n",
      "------------------------------------------------------------\n",
      "âœ… Auto-dashboard is now active! Check the summary and failure dropdown above.\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ AUTO-RUN ALL BENCHMARKS + DASHBOARD\n",
    "\n",
    "print(\"ðŸŽ›ï¸ STARTING AUTO-RUNNING DASHBOARD\")\n",
    "print(\"\" + \"=\"*60)\n",
    "print(\"ðŸš€ This will automatically run ALL benchmarks and show results\")\n",
    "print(\"ðŸ“Š Summary page shows overall statistics\")\n",
    "print(\"ðŸ” Dropdown shows individual benchmark failures and stages\")\n",
    "print(\"\" + \"=\"*60)\n",
    "print()\n",
    "\n",
    "# Launch the auto-running dashboard\n",
    "print(\"ðŸŽ¯ Launching auto-dashboard (this will run all MLIR files)...\")\n",
    "dashboard_widget = auto_dashboard.create_dashboard(auto_run=True)\n",
    "\n",
    "if dashboard_widget:\n",
    "    display(dashboard_widget)\n",
    "else:\n",
    "    print(\"ðŸ’¡ Dashboard results shown above\")\n",
    "\n",
    "print()\n",
    "print(\"\" + \"-\"*60)\n",
    "print(\"ðŸŽ® Dashboard Features:\")\n",
    "print(\"   ðŸ“Š Summary section shows total runs, success rate, runtime stats\")\n",
    "print(\"   ðŸ“ˆ Charts show success distribution and runtime histogram\")\n",
    "print(\"   ðŸ” Failure dropdown lists all failed benchmarks with failure stage\")\n",
    "print(\"   ðŸ“‹ Select a failed benchmark to see detailed error analysis\")\n",
    "print(\"   ðŸ”„ Refresh button updates results, Clear button resets\")\n",
    "print(\"   ðŸš€ Run All button re-runs all benchmarks\")\n",
    "print(\"\" + \"-\"*60)\n",
    "print(\"âœ… Auto-dashboard is now active! Check the summary and failure dropdown above.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FABulous_fork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
